# üß† Entendendo o Q-Learning no Jogo da Velha

Este documento explica a l√≥gica matem√°tica e pr√°tica por tr√°s da IA usada neste projeto de Jogo da Velha com Q-Learning.

---

## ü§ñ O que √© Q-Learning?

**Q-Learning** √© um algoritmo de aprendizado por refor√ßo que permite a um agente aprender uma pol√≠tica √≥tima de a√ß√µes com base em tentativas, erros e recompensas.

---

## üßÆ A Equa√ß√£o de Atualiza√ß√£o

A f√≥rmula usada para atualizar os valores Q √©:

\\[
Q(s, a) \\leftarrow Q(s, a) + \\alpha \\left[ r + \\gamma \\max_{a'} Q(s', a') - Q(s, a) \\right]
\\]

Onde:

- `s` ‚Üí estado atual
- `a` ‚Üí a√ß√£o executada
- `r` ‚Üí recompensa recebida ap√≥s a√ß√£o
- `s'` ‚Üí pr√≥ximo estado
- `Œ±` (alpha) ‚Üí taxa de aprendizado
- `Œ≥` (gamma) ‚Üí fator de desconto do futuro
- `max Q(s', a')` ‚Üí melhor valor estimado da pr√≥xima jogada

---

## üß† Como isso √© aplicado no jogo

### Estados (`s`)
S√£o representa√ß√µes do tabuleiro, como uma string `'XOX O X O'`.

### A√ß√µes (`a`)
S√£o coordenadas dispon√≠veis no tabuleiro, como `(0, 2)`.

### Recompensas (`r`)
- Vit√≥ria: `+1`
- Derrota: `-1`
- Empate: `0`

---

## üé≤ Explora√ß√£o vs Explora√ß√£o

A IA usa **Œµ-greedy** para decidir entre:

- **Explorar** jogadas novas: com probabilidade `Œµ`
- **Explorar** jogadas aprendidas: com probabilidade `1 - Œµ`

O valor de `Œµ` decai com o tempo:

```python
epsilon *= epsilon_decay  # at√© atingir epsilon_min
```
